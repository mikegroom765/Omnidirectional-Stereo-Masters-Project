import pickle
from OCamCalib_model import *
from improvedOCamCalib import *
from perspective_undistortion_LUT_OCamCalib import *
from PSMNet.models import *
import cv2 as cv
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torch.nn.functional as F
import numpy as np

# This code is for generating disparity maps from pictures taken for the experiment, is separate from the main code
# It uses calibration files generated by the main piece of code, as well as calib_result.txt files generated by the
# ImprovedOCamCalib MatLab code.

scale_factor = 2.5

OCamCalibDir = "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\data\\calibration_parameters_OCamCalib"
OCamCalibFrontOut = "\\front_camera_params_OCam.xml"
OCamCalibBackOut = "\\back_camera_params_Ocam.xml"
OCamCalibTopFront = "\\calib_results_tf.txt"
OCamCalibTopBack = "\\calib_results_tb.txt"
OCamCalibBotFront = "\\calib_results_bf.txt"
OCamCalibBotBack = "\\calib_results_bb.txt"

menu_flag = 0
omnidir_flag = 0
improved_flag = 0
both_flag = 0

model_path = "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\PSMNet\\pretrained_model_KITTI2015.tar"
model = stackhourglass(192)
model = nn.DataParallel(model, device_ids=[0])
model.cuda()
state_dict = torch.load(model_path)
model.load_state_dict(state_dict['state_dict'])
model.eval()

def test(imgL, imgR):

    imgL = imgL.cuda()
    imgR = imgR.cuda()

    with torch.no_grad():
        disp = model(imgL, imgR)

    disp = torch.squeeze(disp)
    pred_disp = disp.data.cpu().numpy()

    return pred_disp

def OpenCV():

    # Load previous front camera calibration (OpenCV omnidir)
    frontInFile = open(
        "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\data\\calibration_parameters_OCV\\front_camera_params_OCV.xml",
        'rb')
    frontCameras = pickle.load(frontInFile)
    frontInFile.close()

    # Load previous back camera caibration (OpenCV omnidir)
    backInFile = open(
        "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\data\\calibration_parameters_OCV\\back_camera_params_OCV.xml",
        'rb')
    backCameras = pickle.load(backInFile)
    backInFile.close()

    knew = np.array([[640 / (np.pi * 19 / 18), 0, 0], [0, 640 / (np.pi * 19 / 18), 0], [0, 0, 1]], np.double)

    R1F, R2F = cv.omnidir.stereoRectify(frontCameras.rvec, frontCameras.tvec)
    R1B, R2B = cv.omnidir.stereoRectify(backCameras.rvec, backCameras.tvec)

    mapTF1, mapTF2 = cv.omnidir.initUndistortRectifyMap(frontCameras.K1, frontCameras.D1, frontCameras.xiT,
                                                        R1F, knew, (640, 640), cv.CV_32FC1, #  R1F
                                                        cv.omnidir.RECTIFY_LONGLATI)
    mapBF1, mapBF2 = cv.omnidir.initUndistortRectifyMap(frontCameras.K2, frontCameras.D2, frontCameras.xiB,
                                                        R2F, knew, (640, 640), cv.CV_32FC1, #  R2F
                                                        cv.omnidir.RECTIFY_LONGLATI)
    mapTB1, mapTB2 = cv.omnidir.initUndistortRectifyMap(backCameras.K1, backCameras.D1, backCameras.xiT,
                                                        R1B, knew, (640, 640), cv.CV_32FC1,
                                                        cv.omnidir.RECTIFY_LONGLATI)
    mapBB1, mapBB2 = cv.omnidir.initUndistortRectifyMap(backCameras.K2, backCameras.D2, backCameras.xiB,
                                                        R2B, knew, (640, 640), cv.CV_32FC1,
                                                        cv.omnidir.RECTIFY_LONGLATI)

    sgbm = cv.StereoSGBM_create(minDisparity=0,
                                numDisparities=16 * 8,
                                blockSize=3,
                                P1=4 * 3 * 3,
                                P2=32 * 3 * 3,
                                disp12MaxDiff=1,
                                preFilterCap=63,
                                uniquenessRatio=10,
                                speckleWindowSize=100,
                                speckleRange=32)

    left_matcher = sgbm
    right_matcher = cv.ximgproc.createRightMatcher(left_matcher)

    wls_lmbda = 800
    wls_sigma = 1.2

    wls_filter = cv.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)
    wls_filter.setLambda(wls_lmbda)
    wls_filter.setSigmaColor(wls_sigma)

    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]

    infer_transform = transforms.Compose([transforms.ToTensor(),
                                          transforms.Normalize(mean=mean, std=std)])

    tfImgList = sorted(glob.glob("C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\tf\\tf_*.bmp"))
    tbImgList = sorted(glob.glob("C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\tb\\tb_*.bmp"))
    bfImgList = sorted(glob.glob("C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\bf\\bf_*.bmp"))
    bbImgList = sorted(glob.glob("C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\bb\\bb_*.bmp"))

    menu_flag = 0

    while menu_flag == 0:
        save_rectified_images = input("Would you like to save the rectified images? (y/n): ")
        if save_rectified_images == "y" or save_rectified_images == "n":
            menu_flag = 1

    for idx, value in enumerate(tfImgList):
        tf_colour = cv.imread(tfImgList[idx])
        bf_colour = cv.imread(bfImgList[idx])
        
        left_frame_front = cv.remap(tf_colour, mapTF1, mapTF2, interpolation=cv.INTER_LINEAR, borderMode = cv.BORDER_CONSTANT)
        right_frame_front = cv.remap(bf_colour, mapBF1, mapBF2, interpolation=cv.INTER_LINEAR, borderMode = cv.BORDER_CONSTANT)

        front_rectified = np.full((640, 1280, 3), (0, 0, 0), dtype=np.uint8)
        front_rectified[0:640, 0:640] = left_frame_front
        front_rectified[0:640, 640:1280] = right_frame_front

        for lines in range(7):
            lines += 1
            cv.line(front_rectified, (0, (80 * lines)), (1280, (80 * lines)), (0, 0, 255))

        if save_rectified_images == 'y':

            tf_name = "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\RectifiedImages\\Omnidir\\tf\\tf_" + str(idx) + ".bmp"
            bf_name = "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\RectifiedImages\\Omnidir\\bf\\bf_" + str(idx) + ".bmp"

            cv.imwrite(tf_name, left_frame_front)
            cv.imwrite(bf_name, right_frame_front)

        disparity_front_sgbm = sgbm.compute(left_frame_front, right_frame_front)
        _, disparity_front_sgbm = cv.threshold(disparity_front_sgbm, 0, 128, cv.THRESH_TOZERO)
        disparity_scaled_front_sgbm = (disparity_front_sgbm / 16.).astype(np.uint8)
        disparity_to_display_front_sgbm = (disparity_scaled_front_sgbm * (256. / 128)).astype(np.uint8)

        grayL = cv.cvtColor(left_frame_front, cv.COLOR_BGR2GRAY)
        grayR = cv.cvtColor(right_frame_front, cv.COLOR_BGR2GRAY)

        displ = left_matcher.compute(cv.UMat(grayL), cv.UMat(grayR))  # .astype(np.int16) # tf_img, bf_img
        dispr = right_matcher.compute(cv.UMat(grayR), cv.UMat(grayL))  # .astype(np.int16)
        displ = np.int16(cv.UMat.get(displ))
        dispr = np.int16(cv.UMat.get(dispr))
        disparity_front_wls = wls_filter.filter(displ, grayL, None, dispr)

        _, disparity_front_wls = cv.threshold(disparity_front_wls, 0, 128, cv.THRESH_TOZERO)
        disparity_scaled_front_wls = (disparity_front_wls / 16.).astype(np.uint8)
        disparity_to_display_wls = (disparity_scaled_front_wls * (256. / 128)).astype(np.uint8)

        img1 = cv.cvtColor(left_frame_front, cv.COLOR_BGR2RGB)
        img2 = cv.cvtColor(right_frame_front, cv.COLOR_BGR2RGB)
        img1 = infer_transform(img1)
        img2 = infer_transform(img2)

        if img1.shape[1] % 16 != 0:
            times = img1.shape[1] // 16
            top_pad = (times + 1) * 16 - img1.shape[1]
        else:
            top_pad = 0

        if img1.shape[2] % 16 != 0:
            times = img1.shape[2] // 16
            right_pad = (times + 1) * 16 - img1.shape[2]

        else:
            right_pad = 0

        img1 = F.pad(img1, (0, right_pad, top_pad, 0)).unsqueeze(0)
        img2 = F.pad(img2, (0, right_pad, top_pad, 0)).unsqueeze(0)

        pred_disp = test(img1, img2)
        PSMNet_to_display_front = (pred_disp * (256 / 192)).astype('uint8')
        PSMNet_scaled_front = pred_disp.astype('uint8')

        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCV\\SGBM\\front\\front_" + str(
                idx) + ".bmp", disparity_scaled_front_sgbm)
        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCV\\SGBM_WLS\\front\\front_" + str(
                idx) + ".bmp", disparity_scaled_front_wls)
        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCV\\PSMNet\\front\\front_" + str(
                idx) + ".bmp", PSMNet_scaled_front)

    for idx, value in enumerate(tbImgList):
        tb_colour = cv.imread(tbImgList[idx])
        bb_colour = cv.imread(bbImgList[idx])

        left_frame_back = cv.remap(tb_colour, mapTB1, mapTB2, interpolation=cv.INTER_LINEAR,
                                   borderMode=cv.BORDER_CONSTANT)
        right_frame_back = cv.remap(bb_colour, mapBB1, mapBB2, interpolation=cv.INTER_LINEAR,
                                    borderMode=cv.BORDER_CONSTANT)

        if save_rectified_images == 'y':

            tb_name = "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\RectifiedImages\\Omnidir\\tb\\tb_" + str(
                idx) + ".bmp"
            bb_name = "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\RectifiedImages\\Omnidir\\bb\\bb_" + str(
                idx) + ".bmp"

            cv.imwrite(tb_name, left_frame_back)
            cv.imwrite(bb_name, right_frame_back)

        disparity_back_sgbm = sgbm.compute(left_frame_back, right_frame_back)
        _, disparity_back_sgbm = cv.threshold(disparity_back_sgbm, 0, 128, cv.THRESH_TOZERO)
        disparity_scaled_back_sgbm = (disparity_back_sgbm / 16.).astype(np.uint8)
        disparity_to_display_back_sgbm = (disparity_scaled_back_sgbm * (256. / 128)).astype(np.uint8)

        grayL = cv.cvtColor(left_frame_back, cv.COLOR_BGR2GRAY)
        grayR = cv.cvtColor(right_frame_back, cv.COLOR_BGR2GRAY)

        displ = left_matcher.compute(cv.UMat(grayL), cv.UMat(grayR))  # .astype(np.int16) # tf_img, bf_img
        dispr = right_matcher.compute(cv.UMat(grayR), cv.UMat(grayL))  # .astype(np.int16)
        displ = np.int16(cv.UMat.get(displ))
        dispr = np.int16(cv.UMat.get(dispr))
        disparity_back_wls = wls_filter.filter(displ, grayL, None, dispr)

        _, disparity_back_wls = cv.threshold(disparity_back_wls, 0, 128, cv.THRESH_TOZERO)
        disparity_scaled_back_wls = (disparity_back_wls / 16.).astype(np.uint8)
        disparity_to_display_wls = (disparity_scaled_back_wls * (256. / 128)).astype(np.uint8)

        img1 = cv.cvtColor(left_frame_back, cv.COLOR_BGR2RGB)
        img2 = cv.cvtColor(right_frame_back, cv.COLOR_BGR2RGB)
        img1 = infer_transform(img1)
        img2 = infer_transform(img2)

        if img1.shape[1] % 16 != 0:
            times = img1.shape[1] // 16
            top_pad = (times + 1) * 16 - img1.shape[1]
        else:
            top_pad = 0

        if img1.shape[2] % 16 != 0:
            times = img1.shape[2] // 16
            right_pad = (times + 1) * 16 - img1.shape[2]

        else:
            right_pad = 0

        img1 = F.pad(img1, (0, right_pad, top_pad, 0)).unsqueeze(0)
        img2 = F.pad(img2, (0, right_pad, top_pad, 0)).unsqueeze(0)

        pred_disp = test(img1, img2)
        PSMNet_to_display_back = (pred_disp * (256 / 192)).astype('uint16')
        PSMNet_scaled_back = pred_disp.astype('uint8')

        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCV\\SGBM\\back\\back_" + str(
                idx) + ".bmp", disparity_scaled_back_sgbm)
        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCV\\SGBM_WLS\\back\\back_" + str(
                idx) + ".bmp", disparity_scaled_back_wls)
        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCV\\PSMNet\\back\\back_" + str(
                idx) + ".bmp", PSMNet_scaled_back)

def OCamCalib():
    # Load previous front camera calibration
    frontInFile = open(
        "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\data\\calibration_parameters_OCamCalib\\front_camera_params_OCam.xml",
        'rb')
    frontCameras = pickle.load(frontInFile)
    frontInFile.close()

    # Load previous back camera caibration
    backInFile = open(
        "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\data\\calibration_parameters_OCamCalib\\back_camera_params_Ocam.xml",
        'rb')
    backCameras = pickle.load(backInFile)
    backInFile.close()

    menu_flag = 0

    while menu_flag == 0:
        save_rectified_images = input("Would you like to save the rectified images? (y/n): ")
        if save_rectified_images == "y" or save_rectified_images == "n":
            menu_flag = 1

    print("Creating LUT's..")

    OCam_top_front = OCamCalib_model()
    OCam_top_back = OCamCalib_model()
    OCam_bot_front = OCamCalib_model()
    OCam_bot_back = OCamCalib_model()

    OCam_top_front.readOCamFile(OCamCalibDir + OCamCalibTopFront)
    OCam_top_back.readOCamFile(OCamCalibDir + OCamCalibTopBack)
    OCam_bot_front.readOCamFile(OCamCalibDir + OCamCalibBotFront)
    OCam_bot_back.readOCamFile(OCamCalibDir + OCamCalibBotBack)

    tf_mapx, tf_mapy = perspective_undistortion_LUT(OCam_top_front, scale_factor, 640, 640, 640, 640)
    tb_mapx, tb_mapy = perspective_undistortion_LUT(OCam_top_back, scale_factor, 640, 640, 640, 640)
    bf_mapx, bf_mapy = perspective_undistortion_LUT(OCam_bot_front, scale_factor, 640, 640, 640, 640)
    bb_mapx, bb_mapy = perspective_undistortion_LUT(OCam_bot_back, scale_factor, 640, 640, 640, 640)

    print("Done!")

    R1F, R2F, P1F, P2F, QF, validPix1F, validPix2F = cv.stereoRectify(frontCameras.K1, frontCameras.D1, frontCameras.K2,
                                                                      frontCameras.D2, (1280, 1280), frontCameras.rvec,
                                                                      frontCameras.tvec)

    R1B, R2B, P1B, P2B, QB, validPix1B, validPix2B = cv.stereoRectify(backCameras.K1, backCameras.D1, backCameras.K2,
                                                                      backCameras.D2, (1280, 1280), backCameras.rvec,
                                                                      backCameras.tvec)

    mapTF1, mapTF2 = cv.initUndistortRectifyMap(frontCameras.K1, frontCameras.D1, R1F, None, (1280, 1280), cv.CV_32FC1)

    mapBF1, mapBF2 = cv.initUndistortRectifyMap(frontCameras.K2, frontCameras.D2, R2F, None, (1280, 1280), cv.CV_32FC1)

    mapTB1, mapTB2 = cv.initUndistortRectifyMap(backCameras.K1, backCameras.D1, R1B, None, (1280, 1280), cv.CV_32FC1)

    mapBB1, mapBB2 = cv.initUndistortRectifyMap(backCameras.K2, backCameras.D2, R2B, None, (1280, 1280), cv.CV_32FC1)

    sgbm = cv.StereoSGBM_create(minDisparity=0,
                                numDisparities=16 * 8,
                                blockSize=3,
                                P1=8 * 3 * 3 * 3,
                                P2=64 * 3 * 3 * 3,
                                disp12MaxDiff=160,
                                preFilterCap=32,
                                uniquenessRatio=8,
                                speckleWindowSize=200,
                                speckleRange=2)

    left_matcher = sgbm
    right_matcher = cv.ximgproc.createRightMatcher(left_matcher)

    wls_lmbda = 800
    wls_sigma = 1.2

    wls_filter = cv.ximgproc.createDisparityWLSFilter(matcher_left=left_matcher)
    wls_filter.setLambda(wls_lmbda)
    wls_filter.setSigmaColor(wls_sigma)

    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]

    infer_transform = transforms.Compose([transforms.ToTensor(),
                                          transforms.Normalize(mean=mean, std=std)])

    tfImgList = sorted(glob.glob("C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\OCam_Experiment\\tf\\tf_*.bmp"))
    tbImgList = sorted(glob.glob("C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\OCam_Experiment\\tb\\tb_*.bmp"))
    bfImgList = sorted(glob.glob("C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\OCam_Experiment\\bf\\bf_*.bmp"))
    bbImgList = sorted(glob.glob("C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\OCam_Experiment\\bb\\bb_*.bmp"))


    for idx, value in enumerate(tfImgList):
        tf_colour = cv.imread(tfImgList[idx])
        bf_colour = cv.imread(bfImgList[idx])

        tf_colour = pad_image(tf_colour, 1280)
        bf_colour = pad_image(bf_colour, 1280)

        undistorted_tf = cv.remap(tf_colour, tf_mapx, tf_mapy, cv.INTER_LINEAR, borderMode=cv.BORDER_WRAP + cv.BORDER_CONSTANT) # borderMode=cv.BORDER_WRAP + cv.BORDER_CONSTANT
        undistorted_bf = cv.remap(bf_colour, bf_mapx, bf_mapy, cv.INTER_LINEAR, borderMode=cv.BORDER_WRAP + cv.BORDER_CONSTANT)

        left_frame_front = cv.remap(undistorted_tf, mapTF1, mapTF2, cv.INTER_LINEAR, borderMode=cv.BORDER_CONSTANT)
        right_frame_front = cv.remap(undistorted_bf, mapBF1, mapBF2, cv.INTER_LINEAR, borderMode=cv.BORDER_CONSTANT)

        left_frame_front = cv.transpose(left_frame_front)
        left_frame_front = cv.flip(left_frame_front, 0)
        right_frame_front = cv.transpose(right_frame_front)
        right_frame_front = cv.flip(right_frame_front, 0)

        if save_rectified_images == 'y':

            tf_name = "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\RectifiedImages\\ImprovedOCamCalib\\Scale_factor_" + str(
                scale_factor) + "\\tf\\tf_" + str(idx) + ".bmp"
            bf_name = "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\RectifiedImages\\ImprovedOCamCalib\\Scale_factor_" + str(
                scale_factor) + "\\bf\\bf_" + str(idx) + ".bmp"

            cv.imwrite(tf_name, left_frame_front)
            cv.imwrite(bf_name, right_frame_front)

        disparity_front_sgbm = sgbm.compute(left_frame_front, right_frame_front)
        _, disparity_front_sgbm = cv.threshold(disparity_front_sgbm, 0, 128, cv.THRESH_TOZERO)
        disparity_scaled_front_sgbm = (disparity_front_sgbm / 16.).astype(np.uint8)
        disparity_to_display_front_sgbm = (disparity_scaled_front_sgbm * (256. / 128)).astype(np.uint8)

        grayL = cv.cvtColor(left_frame_front, cv.COLOR_BGR2GRAY)
        grayR = cv.cvtColor(right_frame_front, cv.COLOR_BGR2GRAY)

        displ = left_matcher.compute(cv.UMat(grayL), cv.UMat(grayR))  # .astype(np.int16) # tf_img, bf_img
        dispr = right_matcher.compute(cv.UMat(grayR), cv.UMat(grayL))  # .astype(np.int16)
        displ = np.int16(cv.UMat.get(displ))
        dispr = np.int16(cv.UMat.get(dispr))
        disparity_front_wls = wls_filter.filter(displ, grayL, None, dispr)

        _, disparity_front_wls = cv.threshold(disparity_front_wls, 0, 128, cv.THRESH_TOZERO)
        disparity_scaled_front_wls = (disparity_front_wls / 16.).astype(np.uint8)
        disparity_to_display_wls = (disparity_scaled_front_wls * (256. / 128)).astype(np.uint8)

        img1 = cv.cvtColor(left_frame_front, cv.COLOR_BGR2RGB)
        img2 = cv.cvtColor(right_frame_front, cv.COLOR_BGR2RGB)
        img1 = img1[0: 1280, 400: 800]
        img2 = img2[0: 1280, 400: 800]
        img1 = infer_transform(img1)
        img2 = infer_transform(img2)

        if img1.shape[1] % 16 != 0:
            times = img1.shape[1] // 16
            top_pad = (times + 1) * 16 - img1.shape[1]
        else:
            top_pad = 0

        if img1.shape[2] % 16 != 0:
            times = img1.shape[2] // 16
            right_pad = (times + 1) * 16 - img1.shape[2]

        else:
            right_pad = 0

        img1 = F.pad(img1, (0, right_pad, top_pad, 0)).unsqueeze(0)
        img2 = F.pad(img2, (0, right_pad, top_pad, 0)).unsqueeze(0)

        pred_disp = test(img1, img2)
        PSMNet_to_display_front = (pred_disp * (256 / 192)).astype('uint8')
        PSMNet_scaled_front = pred_disp.astype('uint8')

        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCam\\test\\sf2.5\\SGBM\\front\\front_" + str(
                idx) + ".bmp", disparity_scaled_front_sgbm)
        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCam\\test\\sf2.5\\SGBM_WLS\\front\\front_" + str(
                idx) + ".bmp", disparity_scaled_front_wls)
        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCam\\test\\sf2.5\\PSMNet\\front\\front_" + str(
                idx) + ".bmp", PSMNet_scaled_front)


    for idx, value in enumerate(tbImgList):
        tb_colour = cv.imread(tbImgList[idx])
        bb_colour = cv.imread(bbImgList[idx])

        tb_colour = pad_image(tb_colour, 1280)
        bb_colour = pad_image(bb_colour, 1280)

        undistorted_tb = cv.remap(tb_colour, tb_mapx, tb_mapy, cv.INTER_LINEAR,
                                  borderMode=cv.BORDER_WRAP + cv.BORDER_CONSTANT)
        undistorted_bb = cv.remap(bb_colour, bb_mapx, bb_mapy, cv.INTER_LINEAR,
                                  borderMode=cv.BORDER_WRAP + cv.BORDER_CONSTANT)

        left_frame_back = cv.remap(undistorted_tb, mapTB1, mapTB2, cv.INTER_LINEAR, borderMode=cv.BORDER_CONSTANT)
        right_frame_back = cv.remap(undistorted_bb, mapBB1, mapBB2, cv.INTER_LINEAR, borderMode=cv.BORDER_CONSTANT)

        left_frame_back = cv.transpose(left_frame_back)
        left_frame_back = cv.flip(left_frame_back, 0)
        right_frame_back = cv.transpose(right_frame_back)
        right_frame_back = cv.flip(right_frame_back, 0)

        if save_rectified_images == 'y':
            tb_name = "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\RectifiedImages\\ImprovedOCamCalib\\Scale_factor_" + str(
                scale_factor) + "\\tb\\tb_" + str(idx) + ".bmp"
            bb_name = "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\RectifiedImages\\ImprovedOCamCalib\\Scale_factor_" + str(
                scale_factor) + "\\bb\\bb_" + str(idx) + ".bmp"

            cv.imwrite(tb_name, left_frame_back)
            cv.imwrite(bb_name, right_frame_back)

        disparity_back_sgbm = sgbm.compute(left_frame_back, right_frame_back)
        _, disparity_back_sgbm = cv.threshold(disparity_back_sgbm, 0, 128, cv.THRESH_TOZERO)
        disparity_scaled_back_sgbm = (disparity_back_sgbm / 16.).astype(np.uint8)
        disparity_to_display_back_sgbm = (disparity_scaled_back_sgbm * (256. / 128)).astype(np.uint8)

        grayL = cv.cvtColor(left_frame_back, cv.COLOR_BGR2GRAY)
        grayR = cv.cvtColor(right_frame_back, cv.COLOR_BGR2GRAY)

        displ = left_matcher.compute(cv.UMat(grayL), cv.UMat(grayR))
        dispr = right_matcher.compute(cv.UMat(grayR), cv.UMat(grayL))
        displ = np.int16(cv.UMat.get(displ))
        dispr = np.int16(cv.UMat.get(dispr))
        disparity_back_wls = wls_filter.filter(displ, grayL, None, dispr)

        _, disparity_back_wls = cv.threshold(disparity_back_wls, 0, 128, cv.THRESH_TOZERO)
        disparity_scaled_back_wls = (disparity_back_wls / 16.).astype(np.uint8)
        disparity_to_display_wls = (disparity_scaled_back_wls * (256. / 128)).astype(np.uint8)

        img1 = cv.cvtColor(left_frame_back, cv.COLOR_BGR2RGB)
        img2 = cv.cvtColor(right_frame_back, cv.COLOR_BGR2RGB)
        img1 = img1[0: 1280, 400: 800]
        img2 = img2[0: 1280, 400: 800]
        img1 = infer_transform(img1)
        img2 = infer_transform(img2)

        if img1.shape[1] % 16 != 0:
            times = img1.shape[1] // 16
            top_pad = (times + 1) * 16 - img1.shape[1]
        else:
            top_pad = 0

        if img1.shape[2] % 16 != 0:
            times = img1.shape[2] // 16
            right_pad = (times + 1) * 16 - img1.shape[2]

        else:
            right_pad = 0

        img1 = F.pad(img1, (0, right_pad, top_pad, 0)).unsqueeze(0)
        img2 = F.pad(img2, (0, right_pad, top_pad, 0)).unsqueeze(0)

        pred_disp = test(img1, img2)
        PSMNet_to_display_back = (pred_disp * (256 / 192)).astype('uint8')
        PSMNet_scaled_back = pred_disp.astype('uint8')

        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCam\\test\\sf2.5\\SGBM\\back\\back_" + str(
                idx) + ".bmp", disparity_scaled_back_sgbm)
        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCam\\test\\sf2.5\\SGBM_WLS\\back\\back_" + str(
                idx) + ".bmp", disparity_scaled_back_wls)
        cv.imwrite(
            "C:\\Users\\Len\\PycharmProjects\\OmnidirProject\\Experiment\\disparity_maps\\OCam\\test\\sf2.5\\PSMNet\\back\\back_" + str(
                idx) + ".bmp", PSMNet_scaled_back)


while menu_flag == 0:
    user_input = input("Please choose which calibraion method to use:\n   - OpenCV omnidir module: o\n   - ImprovedOCamCalib: i\n   - Both: b\n")
    if user_input == "o":
        omnidir_flag = 1
        menu_flag = 1
    if user_input == "i":
        improved_flag = 1
        menu_flag = 1
    if user_input == "b":
        both_flag = 1
        menu_flag = 1

if omnidir_flag == 1:
    OpenCV()

if improved_flag == 1:
    OCamCalib()

if both_flag == 1:
    OpenCV()
    OCamCalib()

def pad_image(img, pad):

    h, w, c = np.shape(img)
    result = np.full((pad, pad, c), (0, 0, 0), dtype=np.uint8)

    pad_h = (pad - h) // 2
    pad_w = (pad - w) // 2

    print("padh", pad_h)
    print("Padw", pad_w)

    result[pad_h:pad_h + h, pad_w:pad_w + w] = img

    return result